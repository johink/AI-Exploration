{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle\n",
    "import imageio\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torch.autograd import Variable\n",
    "from random import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160\n",
    "Z_DIMENSION = 32\n",
    "BATCH_SIZE = 36\n",
    "NUM_CHANNELS = 3\n",
    "NUM_ITERATIONS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoomFrameDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_location, transform=None):\n",
    "        \"\"\"\n",
    "        video_location (string): Path to the video file\n",
    "        transform (function, optional): Transforms to apply\n",
    "        \"\"\"\n",
    "        self.video_reader = imageio.get_reader(video_location,  'ffmpeg')\n",
    "        self.frames = [PIL.Image.fromarray(self.video_reader.get_data(idx)) \n",
    "                       for idx in range(len(self.video_reader)) \n",
    "                       if idx % 4 == 0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.frames[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "img_trans = transforms.Compose([transforms.Resize(IMG_SIZE),\n",
    "                                transforms.CenterCrop(IMG_SIZE),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                               ])\n",
    "\n",
    "doom_data = DoomFrameDataset(\"data/doom_gameplay.mp4\", img_trans)\n",
    "\n",
    "doom_loader = torch.utils.data.DataLoader(doom_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoomGenerator(nn.Module):\n",
    "    def __init__(self, hidden_units = 128):\n",
    "        super(DoomGenerator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(Z_DIMENSION, hidden_units*32, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(hidden_units*32)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_units*32, hidden_units*16, 4, 1, 0)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(hidden_units*16)\n",
    "        self.deconv3 = nn.ConvTranspose2d(hidden_units*16, hidden_units*8, 4, 1, 0)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(hidden_units*8)\n",
    "        self.deconv4 = nn.ConvTranspose2d(hidden_units*8, hidden_units*4, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(hidden_units*4)\n",
    "        self.deconv5 = nn.ConvTranspose2d(hidden_units*4, hidden_units*2, 4, 2, 1)\n",
    "        self.deconv5_bn = nn.BatchNorm2d(hidden_units*2)\n",
    "        self.deconv6 = nn.ConvTranspose2d(hidden_units*2, hidden_units, 4, 2, 1)\n",
    "        self.deconv6_bn = nn.BatchNorm2d(hidden_units)\n",
    "        self.deconv7 = nn.ConvTranspose2d(hidden_units, NUM_CHANNELS, 4, 2, 1)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    def forward(self, z_data):\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(z_data)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = F.relu(self.deconv5_bn(self.deconv5(x)))\n",
    "        x = F.relu(self.deconv6_bn(self.deconv6(x)))\n",
    "        x = F.tanh(self.deconv7(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "doom_generator = DoomGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoomDiscriminator(nn.Module):\n",
    "    def __init__(self, hidden_units=128):\n",
    "        super(DoomDiscriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(NUM_CHANNELS, hidden_units, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(hidden_units, hidden_units*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(hidden_units*2)\n",
    "        self.conv3 = nn.Conv2d(hidden_units*2, hidden_units*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(hidden_units*4)\n",
    "        self.conv4 = nn.Conv2d(hidden_units*4, hidden_units*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(hidden_units*8)\n",
    "        self.conv5 = nn.Conv2d(hidden_units*8, hidden_units*16, 4, 1, 0)\n",
    "        self.conv5_bn = nn.BatchNorm2d(hidden_units*16)\n",
    "        self.conv6 = nn.Conv2d(hidden_units*16, hidden_units*32, 4, 1, 0)\n",
    "        self.conv6_bn = nn.BatchNorm2d(hidden_units*32)\n",
    "        self.conv7 = nn.Conv2d(hidden_units*32, 1, 4, 1, 0)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = F.leaky_relu(self.conv1(image), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv5_bn(self.conv5(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv6_bn(self.conv6(x)), 0.2)\n",
    "        x = F.sigmoid(self.conv7(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "doom_discriminator = DoomDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoomGenerator(\n",
       "  (deconv1): ConvTranspose2d (32, 4096, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (deconv1_bn): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv2): ConvTranspose2d (4096, 2048, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (deconv2_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv3): ConvTranspose2d (2048, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (deconv3_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv4): ConvTranspose2d (1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (deconv4_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv5): ConvTranspose2d (512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (deconv5_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv6): ConvTranspose2d (256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (deconv6_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv7): ConvTranspose2d (128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doom_discriminator.weight_init(0, .02)\n",
    "doom_discriminator.cuda()\n",
    "\n",
    "#doom_generator.weight_init(0, .02)\n",
    "doom_generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doom_generator.load_state_dict(torch.load('gan_files/gen_latest.pth'))\n",
    "#doom_discriminator.load_state_dict(torch.load('gan_files/disc_latest.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.FloatTensor(BATCH_SIZE, Z_DIMENSION, 1, 1).cuda()\n",
    "fixed_noise = Variable(torch.FloatTensor(BATCH_SIZE, Z_DIMENSION, 1, 1).normal_(0, 1)).cuda()\n",
    "\n",
    "disc_opt = optim.Adam(doom_discriminator.parameters(), lr=.0001, betas=(.5, 0.999))\n",
    "gen_opt = optim.Adam(doom_generator.parameters(), lr=.0001, betas=(.5, 0.999))\n",
    "\n",
    "binary_cross_entropy_loss = nn.BCELoss()\n",
    "\n",
    "disc_scheduler = optim.lr_scheduler.StepLR(disc_opt, 10, .5)\n",
    "gen_scheduler = optim.lr_scheduler.StepLR(gen_opt, 10, .5)\n",
    "\n",
    "added_noise = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25] :: [1/4]\n",
      "        Disc_Real_Loss: 0.4116857945919037 Disc_Fake_Loss: 0.49440664052963257 Gen_Loss: 1.2685251235961914\n",
      "[12/25] :: [2/4]\n",
      "        Disc_Real_Loss: 0.40914639830589294 Disc_Fake_Loss: 0.4656500816345215 Gen_Loss: 1.874472737312317\n",
      "[12/25] :: [3/4]\n",
      "        Disc_Real_Loss: 0.3832114636898041 Disc_Fake_Loss: 0.4555117189884186 Gen_Loss: 1.9223933219909668\n",
      "[12/25] :: [4/4]\n",
      "        Disc_Real_Loss: 0.2888214886188507 Disc_Fake_Loss: 0.5268737077713013 Gen_Loss: 2.0882744789123535\n",
      "[13/25] :: [1/4]\n",
      "        Disc_Real_Loss: 0.43545666337013245 Disc_Fake_Loss: 0.4795427918434143 Gen_Loss: 1.274022102355957\n",
      "[13/25] :: [2/4]\n",
      "        Disc_Real_Loss: 0.3524535596370697 Disc_Fake_Loss: 0.4227713644504547 Gen_Loss: 2.1557698249816895\n",
      "[13/25] :: [3/4]\n",
      "        Disc_Real_Loss: 0.25271275639533997 Disc_Fake_Loss: 0.4680973291397095 Gen_Loss: 1.4142323732376099\n",
      "[13/25] :: [4/4]\n",
      "        Disc_Real_Loss: 1.2793246507644653 Disc_Fake_Loss: 0.8484671115875244 Gen_Loss: 0.5126442313194275\n",
      "[14/25] :: [1/4]\n",
      "        Disc_Real_Loss: 0.21824507415294647 Disc_Fake_Loss: 0.4675888419151306 Gen_Loss: 1.2921987771987915\n",
      "[14/25] :: [2/4]\n",
      "        Disc_Real_Loss: 0.15877275168895721 Disc_Fake_Loss: 0.39728039503097534 Gen_Loss: 1.6828900575637817\n",
      "[14/25] :: [3/4]\n",
      "        Disc_Real_Loss: 0.257139652967453 Disc_Fake_Loss: 0.5593732595443726 Gen_Loss: 1.3821783065795898\n",
      "[14/25] :: [4/4]\n",
      "        Disc_Real_Loss: 0.24839752912521362 Disc_Fake_Loss: 0.4252088665962219 Gen_Loss: 1.5492069721221924\n",
      "[15/25] :: [1/4]\n",
      "        Disc_Real_Loss: 0.3551245629787445 Disc_Fake_Loss: 0.45373937487602234 Gen_Loss: 1.5280554294586182\n"
     ]
    }
   ],
   "source": [
    "fake = doom_generator(fixed_noise)\n",
    "utils.save_image(fake.data,\n",
    "        'gan_files/fake_frames_before_training.png',\n",
    "        normalize = True, nrow = 6)\n",
    "\n",
    "for epoch in range(12, NUM_ITERATIONS + 1):\n",
    "    disc_scheduler.step()\n",
    "    gen_scheduler.step()\n",
    "    for repeat in range(1, 5):\n",
    "        for i, data in enumerate(doom_loader, start = 1):\n",
    "\n",
    "            if i == 1 and epoch == 1:\n",
    "                utils.save_image(data, 'gan_files/real_frames.png', normalize = True, nrow = 6)\n",
    "\n",
    "\n",
    "            real_label = Variable(torch.FloatTensor(data.size(0)).uniform_(0.7, 1.2)).cuda()\n",
    "            fake_label = Variable(torch.FloatTensor(noise.size(0)).uniform_(0.0, 0.3)).cuda()\n",
    "\n",
    "            doom_discriminator.zero_grad()\n",
    "            noisy_input = data + torch.FloatTensor(*data.size()).normal_(0, added_noise * .9 ** epoch)\n",
    "            inputv = Variable(noisy_input).cuda()\n",
    "\n",
    "            real_output = doom_discriminator(inputv)\n",
    "\n",
    "\n",
    "            # train with fake\n",
    "            noise.normal_(0, 1)\n",
    "            noisev = Variable(noise).cuda()\n",
    "            fake = doom_generator(noisev)\n",
    "            noisy_fake = fake.data + torch.FloatTensor(*fake.size()).normal_(0, added_noise * .9 ** epoch).cuda()\n",
    "            fake_output = doom_discriminator(Variable(noisy_fake).cuda())\n",
    "\n",
    "            if random() < 0.01:    \n",
    "                disc_real_loss = binary_cross_entropy_loss(real_output.squeeze(), Variable(real_label.data.uniform_(0.0, 0.3)).cuda())\n",
    "                disc_fake_loss = binary_cross_entropy_loss(fake_output.squeeze(), Variable(fake_label.data.uniform_(0.7, 1.2)).cuda())\n",
    "            else:\n",
    "                disc_real_loss = binary_cross_entropy_loss(real_output.squeeze(), real_label)\n",
    "                disc_fake_loss = binary_cross_entropy_loss(fake_output.squeeze(), fake_label)\n",
    "\n",
    "            disc_real_loss.backward()\n",
    "            disc_fake_loss.backward()\n",
    "\n",
    "            disc_loss = disc_real_loss + disc_fake_loss\n",
    "\n",
    "            disc_opt.step()\n",
    "\n",
    "\n",
    "\n",
    "            doom_generator.zero_grad()\n",
    "            output = doom_discriminator(fake)\n",
    "            real_label = Variable(torch.FloatTensor(output.size(0)).fill_(1)).cuda()\n",
    "\n",
    "            gen_loss = binary_cross_entropy_loss(output.squeeze(), real_label)\n",
    "            gen_loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "\n",
    "        print(f\"\"\"[{epoch}/{NUM_ITERATIONS}] :: [{repeat}/{4}]\n",
    "        Disc_Real_Loss: {disc_real_loss.data[0]} Disc_Fake_Loss: {disc_fake_loss.data[0]} Gen_Loss: {gen_loss.data[0]}\"\"\")\n",
    "\n",
    "    fake = doom_generator(fixed_noise)\n",
    "    utils.save_image(fake.data,\n",
    "            f'gan_files/fake_frames_after_epoch_{epoch}.png',\n",
    "            normalize = True, nrow = 6)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(doom_generator.state_dict(), f'gan_files/gen_latest.pth')\n",
    "    torch.save(doom_discriminator.state_dict(), f'gan_files/disc_latest.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
