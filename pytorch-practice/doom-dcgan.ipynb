{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle\n",
    "import imageio\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torch.autograd import Variable\n",
    "from random import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160\n",
    "Z_DIMENSION = 32\n",
    "BATCH_SIZE = 36\n",
    "NUM_CHANNELS = 3\n",
    "NUM_ITERATIONS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoomFrameDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_location, transform=None):\n",
    "        \"\"\"\n",
    "        video_location (string): Path to the video file\n",
    "        transform (function, optional): Transforms to apply\n",
    "        \"\"\"\n",
    "        self.video_reader = imageio.get_reader(video_location,  'ffmpeg')\n",
    "        self.frames = [PIL.Image.fromarray(self.video_reader.get_data(idx)) for idx in range(len(self.video_reader)) if idx % 5 == 0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.frames[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "img_trans = transforms.Compose([transforms.Resize(IMG_SIZE),\n",
    "                                transforms.CenterCrop(IMG_SIZE),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                               ])\n",
    "\n",
    "doom_data = DoomFrameDataset(\"data/doom_gameplay.mp4\", img_trans)\n",
    "\n",
    "doom_loader = torch.utils.data.DataLoader(doom_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoomGenerator(nn.Module):\n",
    "    def __init__(self, hidden_units = 128):\n",
    "        super(DoomGenerator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(Z_DIMENSION, hidden_units*32, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(hidden_units*32)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_units*32, hidden_units*16, 4, 1, 0)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(hidden_units*16)\n",
    "        self.deconv3 = nn.ConvTranspose2d(hidden_units*16, hidden_units*8, 4, 1, 0)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(hidden_units*8)\n",
    "        self.deconv4 = nn.ConvTranspose2d(hidden_units*8, hidden_units*4, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(hidden_units*4)\n",
    "        self.deconv5 = nn.ConvTranspose2d(hidden_units*4, hidden_units*2, 4, 2, 1)\n",
    "        self.deconv5_bn = nn.BatchNorm2d(hidden_units*2)\n",
    "        self.deconv6 = nn.ConvTranspose2d(hidden_units*2, hidden_units, 4, 2, 1)\n",
    "        self.deconv6_bn = nn.BatchNorm2d(hidden_units)\n",
    "        self.deconv7 = nn.ConvTranspose2d(hidden_units, NUM_CHANNELS, 4, 2, 1)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    def forward(self, z_data):\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(z_data)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = F.relu(self.deconv5_bn(self.deconv5(x)))\n",
    "        x = F.relu(self.deconv6_bn(self.deconv6(x)))\n",
    "        x = F.tanh(self.deconv7(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "doom_generator = DoomGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoomDiscriminator(nn.Module):\n",
    "    def __init__(self, hidden_units=128):\n",
    "        super(DoomDiscriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(NUM_CHANNELS, hidden_units, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(hidden_units, hidden_units*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(hidden_units*2)\n",
    "        self.conv3 = nn.Conv2d(hidden_units*2, hidden_units*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(hidden_units*4)\n",
    "        self.conv4 = nn.Conv2d(hidden_units*4, hidden_units*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(hidden_units*8)\n",
    "        self.conv5 = nn.Conv2d(hidden_units*8, hidden_units*16, 4, 1, 0)\n",
    "        self.conv5_bn = nn.BatchNorm2d(hidden_units*16)\n",
    "        self.conv6 = nn.Conv2d(hidden_units*16, hidden_units*32, 4, 1, 0)\n",
    "        self.conv6_bn = nn.BatchNorm2d(hidden_units*32)\n",
    "        self.conv7 = nn.Conv2d(hidden_units*32, 1, 4, 1, 0)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = F.leaky_relu(self.conv1(image), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv5_bn(self.conv5(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv6_bn(self.conv6(x)), 0.2)\n",
    "        x = F.sigmoid(self.conv7(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "doom_discriminator = DoomDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoomGenerator(\n",
       "  (deconv1): ConvTranspose2d (32, 4096, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (deconv1_bn): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv2): ConvTranspose2d (4096, 2048, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (deconv2_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv3): ConvTranspose2d (2048, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (deconv3_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv4): ConvTranspose2d (1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (deconv4_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv5): ConvTranspose2d (512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (deconv5_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv6): ConvTranspose2d (256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (deconv6_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (deconv7): ConvTranspose2d (128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doom_discriminator.weight_init(0, .02)\n",
    "doom_discriminator.cuda()\n",
    "\n",
    "#doom_generator.weight_init(0, .02)\n",
    "doom_generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doom_generator.load_state_dict(torch.load('gan_files/gen_latest.pth'))\n",
    "doom_discriminator.load_state_dict(torch.load('gan_files/disc_latest.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.FloatTensor(BATCH_SIZE, Z_DIMENSION, 1, 1).cuda()\n",
    "fixed_noise = Variable(torch.FloatTensor(BATCH_SIZE, Z_DIMENSION, 1, 1).normal_(0, 1)).cuda()\n",
    "\n",
    "disc_opt = optim.Adam(doom_discriminator.parameters(), lr=.01, betas=(.5, 0.999))\n",
    "gen_opt = optim.Adam(doom_generator.parameters(), lr=.01, betas=(.5, 0.999))\n",
    "\n",
    "binary_cross_entropy_loss = nn.BCELoss()\n",
    "\n",
    "disc_scheduler = optim.lr_scheduler.StepLR(disc_opt, 1, .9)\n",
    "gen_scheduler = optim.lr_scheduler.StepLR(gen_opt, 1, .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43/24] :: [0/69]\n",
      "        Disc_Real_Loss: 0.4632370173931122 Disc_Fake_Loss: 1.3674585819244385 Gen_Loss: 5.913876056671143\n",
      "[43/24] :: [1/69]\n",
      "        Disc_Real_Loss: 4.8354315757751465 Disc_Fake_Loss: 3.6930651664733887 Gen_Loss: 0.07406479865312576\n",
      "[43/24] :: [2/69]\n",
      "        Disc_Real_Loss: 2.0265653133392334 Disc_Fake_Loss: 7.800229549407959 Gen_Loss: 0.8380602598190308\n",
      "[43/24] :: [3/69]\n",
      "        Disc_Real_Loss: 3.613203287124634 Disc_Fake_Loss: 3.5785157680511475 Gen_Loss: 4.099851131439209\n",
      "[43/24] :: [4/69]\n",
      "        Disc_Real_Loss: 0.9341623783111572 Disc_Fake_Loss: 2.4338173866271973 Gen_Loss: 3.518409252166748\n",
      "[43/24] :: [5/69]\n",
      "        Disc_Real_Loss: 2.5925097465515137 Disc_Fake_Loss: 1.853238821029663 Gen_Loss: 3.245856761932373\n",
      "[43/24] :: [6/69]\n",
      "        Disc_Real_Loss: 2.9736878871917725 Disc_Fake_Loss: 1.1424721479415894 Gen_Loss: 0.04421444982290268\n",
      "[43/24] :: [7/69]\n",
      "        Disc_Real_Loss: -0.16866299510002136 Disc_Fake_Loss: 3.4986722469329834 Gen_Loss: 1.8210610151290894\n",
      "[43/24] :: [8/69]\n",
      "        Disc_Real_Loss: 2.165133476257324 Disc_Fake_Loss: 2.4324100017547607 Gen_Loss: 0.34837451577186584\n",
      "[43/24] :: [9/69]\n",
      "        Disc_Real_Loss: 0.5019367337226868 Disc_Fake_Loss: 2.8028886318206787 Gen_Loss: 1.1746801137924194\n",
      "[43/24] :: [10/69]\n",
      "        Disc_Real_Loss: 1.31383216381073 Disc_Fake_Loss: 2.5950136184692383 Gen_Loss: 0.33461177349090576\n",
      "[43/24] :: [11/69]\n",
      "        Disc_Real_Loss: 0.7408393621444702 Disc_Fake_Loss: 3.315228223800659 Gen_Loss: 1.4024028778076172\n",
      "[43/24] :: [12/69]\n",
      "        Disc_Real_Loss: 1.855457067489624 Disc_Fake_Loss: 5.165634632110596 Gen_Loss: 5.576580047607422\n",
      "[43/24] :: [13/69]\n",
      "        Disc_Real_Loss: 3.3011696338653564 Disc_Fake_Loss: 3.994312286376953 Gen_Loss: 4.0788092613220215\n",
      "[43/24] :: [14/69]\n",
      "        Disc_Real_Loss: 0.6013873219490051 Disc_Fake_Loss: 4.47835111618042 Gen_Loss: 1.413362979888916\n",
      "[43/24] :: [15/69]\n",
      "        Disc_Real_Loss: 1.7180204391479492 Disc_Fake_Loss: 5.547434329986572 Gen_Loss: 1.0661898851394653\n",
      "[43/24] :: [16/69]\n",
      "        Disc_Real_Loss: 0.22656355798244476 Disc_Fake_Loss: 3.7303788661956787 Gen_Loss: 0.5783169269561768\n",
      "[43/24] :: [17/69]\n",
      "        Disc_Real_Loss: 0.3697933852672577 Disc_Fake_Loss: 4.476141452789307 Gen_Loss: 1.140978217124939\n",
      "[43/24] :: [18/69]\n",
      "        Disc_Real_Loss: 1.9183591604232788 Disc_Fake_Loss: 15.155656814575195 Gen_Loss: 0.23101681470870972\n",
      "[43/24] :: [19/69]\n",
      "        Disc_Real_Loss: 0.2956555187702179 Disc_Fake_Loss: 5.615905284881592 Gen_Loss: 2.9144277572631836\n",
      "[43/24] :: [20/69]\n",
      "        Disc_Real_Loss: 5.177879333496094 Disc_Fake_Loss: 4.116995811462402 Gen_Loss: 0.10242463648319244\n",
      "[43/24] :: [21/69]\n",
      "        Disc_Real_Loss: -0.45380961894989014 Disc_Fake_Loss: 6.511354923248291 Gen_Loss: 1.1862671375274658\n",
      "[43/24] :: [22/69]\n",
      "        Disc_Real_Loss: 0.8609901666641235 Disc_Fake_Loss: 2.5776045322418213 Gen_Loss: 6.737481594085693\n",
      "[43/24] :: [23/69]\n",
      "        Disc_Real_Loss: 0.3065427243709564 Disc_Fake_Loss: 2.6867971420288086 Gen_Loss: 5.123748779296875\n",
      "[43/24] :: [24/69]\n",
      "        Disc_Real_Loss: 5.785364151000977 Disc_Fake_Loss: 0.484016090631485 Gen_Loss: 1.745134949684143\n",
      "[43/24] :: [25/69]\n",
      "        Disc_Real_Loss: 3.9736714363098145 Disc_Fake_Loss: 3.9606688022613525 Gen_Loss: 5.040213108062744\n",
      "[43/24] :: [26/69]\n",
      "        Disc_Real_Loss: 2.960991621017456 Disc_Fake_Loss: 0.735550045967102 Gen_Loss: 0.0699474960565567\n",
      "[43/24] :: [27/69]\n",
      "        Disc_Real_Loss: 0.2606460452079773 Disc_Fake_Loss: 2.179182767868042 Gen_Loss: 5.868497848510742\n",
      "[43/24] :: [28/69]\n",
      "        Disc_Real_Loss: 2.59741473197937 Disc_Fake_Loss: 1.1958997249603271 Gen_Loss: 5.967457294464111\n",
      "[43/24] :: [29/69]\n",
      "        Disc_Real_Loss: 0.5585270524024963 Disc_Fake_Loss: 2.3222134113311768 Gen_Loss: 2.054697036743164\n",
      "[43/24] :: [30/69]\n",
      "        Disc_Real_Loss: 1.4234950542449951 Disc_Fake_Loss: 0.4653940796852112 Gen_Loss: 0.10630417615175247\n",
      "[43/24] :: [31/69]\n",
      "        Disc_Real_Loss: -0.014867424964904785 Disc_Fake_Loss: 1.7967171669006348 Gen_Loss: 1.3924201726913452\n",
      "[43/24] :: [32/69]\n",
      "        Disc_Real_Loss: 0.6522862911224365 Disc_Fake_Loss: 2.056500196456909 Gen_Loss: 1.912872314453125\n",
      "[43/24] :: [33/69]\n",
      "        Disc_Real_Loss: 1.3895738124847412 Disc_Fake_Loss: 1.3491160869598389 Gen_Loss: 0.132278174161911\n",
      "[43/24] :: [34/69]\n",
      "        Disc_Real_Loss: 2.962984561920166 Disc_Fake_Loss: 2.6231484413146973 Gen_Loss: 0.2679147720336914\n",
      "[43/24] :: [35/69]\n",
      "        Disc_Real_Loss: 0.5485780835151672 Disc_Fake_Loss: 2.5395278930664062 Gen_Loss: 5.92780876159668\n",
      "[43/24] :: [36/69]\n",
      "        Disc_Real_Loss: 3.6858553886413574 Disc_Fake_Loss: 0.654447615146637 Gen_Loss: 1.1150957345962524\n",
      "[43/24] :: [37/69]\n",
      "        Disc_Real_Loss: 0.24224421381950378 Disc_Fake_Loss: 3.0690908432006836 Gen_Loss: 0.9077735543251038\n",
      "[43/24] :: [38/69]\n",
      "        Disc_Real_Loss: 0.7898447513580322 Disc_Fake_Loss: 1.9485249519348145 Gen_Loss: 1.1433043479919434\n",
      "[43/24] :: [39/69]\n",
      "        Disc_Real_Loss: 0.9435189366340637 Disc_Fake_Loss: 3.591817617416382 Gen_Loss: 0.3986148536205292\n",
      "[43/24] :: [40/69]\n",
      "        Disc_Real_Loss: 0.5833072066307068 Disc_Fake_Loss: 2.861724376678467 Gen_Loss: 1.6980701684951782\n",
      "[43/24] :: [41/69]\n",
      "        Disc_Real_Loss: 1.0843195915222168 Disc_Fake_Loss: 3.710329294204712 Gen_Loss: 0.22358958423137665\n",
      "[43/24] :: [42/69]\n",
      "        Disc_Real_Loss: 0.17197637259960175 Disc_Fake_Loss: 5.307687759399414 Gen_Loss: 1.049311876296997\n",
      "[43/24] :: [43/69]\n",
      "        Disc_Real_Loss: 1.1537439823150635 Disc_Fake_Loss: 4.637086868286133 Gen_Loss: 1.3324261903762817\n",
      "[43/24] :: [44/69]\n",
      "        Disc_Real_Loss: 0.5600817203521729 Disc_Fake_Loss: 3.5115888118743896 Gen_Loss: 1.5697312355041504\n",
      "[43/24] :: [45/69]\n",
      "        Disc_Real_Loss: 0.9543368816375732 Disc_Fake_Loss: 2.0612969398498535 Gen_Loss: 0.6646946668624878\n",
      "[43/24] :: [46/69]\n",
      "        Disc_Real_Loss: 0.7928133606910706 Disc_Fake_Loss: 4.978695869445801 Gen_Loss: 1.8325061798095703\n",
      "[43/24] :: [47/69]\n",
      "        Disc_Real_Loss: 1.5450679063796997 Disc_Fake_Loss: 1.90133798122406 Gen_Loss: 1.0162615776062012\n",
      "[43/24] :: [48/69]\n",
      "        Disc_Real_Loss: 0.2902456521987915 Disc_Fake_Loss: 3.4358303546905518 Gen_Loss: 0.555812418460846\n",
      "[43/24] :: [49/69]\n",
      "        Disc_Real_Loss: 0.6966770887374878 Disc_Fake_Loss: 2.5961098670959473 Gen_Loss: 11.227812767028809\n",
      "[43/24] :: [50/69]\n",
      "        Disc_Real_Loss: 0.17465610802173615 Disc_Fake_Loss: 8.79745101928711 Gen_Loss: 15.106632232666016\n",
      "[43/24] :: [51/69]\n",
      "        Disc_Real_Loss: 6.724552631378174 Disc_Fake_Loss: 8.33442211151123 Gen_Loss: 0.1907549649477005\n",
      "[43/24] :: [52/69]\n",
      "        Disc_Real_Loss: 0.3208690583705902 Disc_Fake_Loss: 6.271397113800049 Gen_Loss: 3.2012548446655273\n",
      "[43/24] :: [53/69]\n",
      "        Disc_Real_Loss: 0.07544241845607758 Disc_Fake_Loss: 3.485262870788574 Gen_Loss: 3.3977479934692383\n",
      "[43/24] :: [54/69]\n",
      "        Disc_Real_Loss: 1.0420397520065308 Disc_Fake_Loss: 1.8267968893051147 Gen_Loss: 0.27015912532806396\n",
      "[43/24] :: [55/69]\n",
      "        Disc_Real_Loss: 1.124596118927002 Disc_Fake_Loss: 3.373476266860962 Gen_Loss: 0.28380924463272095\n",
      "[43/24] :: [56/69]\n",
      "        Disc_Real_Loss: 0.8952170610427856 Disc_Fake_Loss: 4.246979236602783 Gen_Loss: 3.43441104888916\n",
      "[43/24] :: [57/69]\n",
      "        Disc_Real_Loss: 0.9003403186798096 Disc_Fake_Loss: 2.0918121337890625 Gen_Loss: 1.682283878326416\n",
      "[43/24] :: [58/69]\n",
      "        Disc_Real_Loss: -0.03289313241839409 Disc_Fake_Loss: 3.120534658432007 Gen_Loss: 2.826934814453125\n",
      "[43/24] :: [59/69]\n",
      "        Disc_Real_Loss: 1.951255202293396 Disc_Fake_Loss: 1.6748158931732178 Gen_Loss: 0.04042508825659752\n",
      "[43/24] :: [60/69]\n",
      "        Disc_Real_Loss: 0.09774250537157059 Disc_Fake_Loss: 3.1217358112335205 Gen_Loss: 1.510553002357483\n",
      "[43/24] :: [61/69]\n",
      "        Disc_Real_Loss: 0.24372249841690063 Disc_Fake_Loss: 1.712390422821045 Gen_Loss: 2.791408061981201\n",
      "[43/24] :: [62/69]\n",
      "        Disc_Real_Loss: 1.0412442684173584 Disc_Fake_Loss: 3.551253080368042 Gen_Loss: 0.5680942535400391\n",
      "[43/24] :: [63/69]\n",
      "        Disc_Real_Loss: 1.0841134786605835 Disc_Fake_Loss: 3.7434539794921875 Gen_Loss: 1.7192507982254028\n",
      "[43/24] :: [64/69]\n",
      "        Disc_Real_Loss: 1.5382609367370605 Disc_Fake_Loss: 3.1183979511260986 Gen_Loss: 9.851810455322266\n",
      "[43/24] :: [65/69]\n",
      "        Disc_Real_Loss: 5.436951637268066 Disc_Fake_Loss: 0.9055582880973816 Gen_Loss: 2.4059934616088867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43/24] :: [66/69]\n",
      "        Disc_Real_Loss: 1.4393641948699951 Disc_Fake_Loss: 2.2190771102905273 Gen_Loss: 3.3635759353637695\n",
      "[43/24] :: [67/69]\n",
      "        Disc_Real_Loss: 1.8088887929916382 Disc_Fake_Loss: 0.5334113836288452 Gen_Loss: 0.08132167905569077\n",
      "[43/24] :: [68/69]\n",
      "        Disc_Real_Loss: 1.164448857307434 Disc_Fake_Loss: 5.037783145904541 Gen_Loss: 3.0055432319641113\n",
      "[43/24] :: [69/69]\n",
      "        Disc_Real_Loss: 15.484395027160645 Disc_Fake_Loss: 3.3707902431488037 Gen_Loss: 0.03602616488933563\n",
      "[44/24] :: [0/69]\n",
      "        Disc_Real_Loss: 0.4349207878112793 Disc_Fake_Loss: 5.072576522827148 Gen_Loss: 1.8556272983551025\n",
      "[44/24] :: [1/69]\n",
      "        Disc_Real_Loss: 0.44048887491226196 Disc_Fake_Loss: 2.354945182800293 Gen_Loss: 5.7324700355529785\n",
      "[44/24] :: [2/69]\n",
      "        Disc_Real_Loss: 2.2628140449523926 Disc_Fake_Loss: 0.9454253315925598 Gen_Loss: 4.247775554656982\n",
      "[44/24] :: [3/69]\n",
      "        Disc_Real_Loss: 0.4251626431941986 Disc_Fake_Loss: 1.7178232669830322 Gen_Loss: 3.772336006164551\n",
      "[44/24] :: [4/69]\n",
      "        Disc_Real_Loss: 2.402825117111206 Disc_Fake_Loss: 0.7536867260932922 Gen_Loss: 1.8141117095947266\n",
      "[44/24] :: [5/69]\n",
      "        Disc_Real_Loss: 0.1663924753665924 Disc_Fake_Loss: 1.2663917541503906 Gen_Loss: 3.670427083969116\n",
      "[44/24] :: [6/69]\n",
      "        Disc_Real_Loss: 0.5914241671562195 Disc_Fake_Loss: 0.5501487851142883 Gen_Loss: 1.0935848951339722\n",
      "[44/24] :: [7/69]\n",
      "        Disc_Real_Loss: 0.16491122543811798 Disc_Fake_Loss: 2.061699390411377 Gen_Loss: 2.4543049335479736\n",
      "[44/24] :: [8/69]\n",
      "        Disc_Real_Loss: 1.220131754875183 Disc_Fake_Loss: 1.828227162361145 Gen_Loss: 0.3373199999332428\n",
      "[44/24] :: [9/69]\n",
      "        Disc_Real_Loss: 0.14158810675144196 Disc_Fake_Loss: 1.9002573490142822 Gen_Loss: 3.315762758255005\n",
      "[44/24] :: [10/69]\n",
      "        Disc_Real_Loss: 0.6972203254699707 Disc_Fake_Loss: 1.655245065689087 Gen_Loss: 7.106517314910889\n",
      "[44/24] :: [11/69]\n",
      "        Disc_Real_Loss: 5.410673141479492 Disc_Fake_Loss: 0.6048046350479126 Gen_Loss: 1.095010757446289\n",
      "[44/24] :: [12/69]\n",
      "        Disc_Real_Loss: 0.6354851126670837 Disc_Fake_Loss: 6.400238037109375 Gen_Loss: 2.2747416496276855\n",
      "[44/24] :: [13/69]\n",
      "        Disc_Real_Loss: 0.6875346302986145 Disc_Fake_Loss: 0.7973673343658447 Gen_Loss: 3.5197548866271973\n",
      "[44/24] :: [14/69]\n",
      "        Disc_Real_Loss: 1.322739601135254 Disc_Fake_Loss: 0.5976095199584961 Gen_Loss: 1.8349666595458984\n",
      "[44/24] :: [15/69]\n",
      "        Disc_Real_Loss: 0.02432103268802166 Disc_Fake_Loss: 1.4264531135559082 Gen_Loss: 2.6761279106140137\n",
      "[44/24] :: [16/69]\n",
      "        Disc_Real_Loss: 0.7191016674041748 Disc_Fake_Loss: 0.4311179220676422 Gen_Loss: 1.1045939922332764\n",
      "[44/24] :: [17/69]\n",
      "        Disc_Real_Loss: 0.13664335012435913 Disc_Fake_Loss: 3.4053547382354736 Gen_Loss: 1.398130178451538\n",
      "[44/24] :: [18/69]\n",
      "        Disc_Real_Loss: 0.5057656764984131 Disc_Fake_Loss: 2.348081588745117 Gen_Loss: 0.4975297749042511\n",
      "[44/24] :: [19/69]\n",
      "        Disc_Real_Loss: 0.2559623718261719 Disc_Fake_Loss: 3.807905435562134 Gen_Loss: 1.9676164388656616\n",
      "[44/24] :: [20/69]\n",
      "        Disc_Real_Loss: 2.1213631629943848 Disc_Fake_Loss: 2.4887266159057617 Gen_Loss: 0.08576716482639313\n"
     ]
    }
   ],
   "source": [
    "fake = doom_generator(fixed_noise)\n",
    "utils.save_image(fake.data,\n",
    "        f'gan_files/fake_frames_before_training.png',\n",
    "        normalize = True, nrow = 6)\n",
    "\n",
    "for epoch in range(NUM_ITERATIONS*10):\n",
    "    disc_scheduler.step()\n",
    "    gen_scheduler.step()\n",
    "    noise_anneal = 0\n",
    "    epoch += 43\n",
    "    for i, data in enumerate(doom_loader):\n",
    "        \n",
    "        if i == 0 and epoch == 0:\n",
    "            utils.save_image(data, 'gan_files/real_frames.png', normalize = True, nrow = 6)\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        \n",
    "        real_label = Variable(torch.FloatTensor(data.size(0)).uniform_(0.7, 1.2)).cuda()\n",
    "        fake_label = Variable(torch.FloatTensor(noise.size(0)).uniform_(0.0, 0.3)).cuda()\n",
    "        \n",
    "        doom_discriminator.zero_grad()\n",
    "        noisy_input = data# + torch.FloatTensor(*data.size()).normal_(0, noise_anneal)\n",
    "        inputv = Variable(noisy_input).cuda()\n",
    "\n",
    "        real_output = doom_discriminator(inputv)\n",
    "\n",
    "\n",
    "        # train with fake\n",
    "        noise.normal_(0, 1)\n",
    "        noisev = Variable(noise).cuda()\n",
    "        fake = doom_generator(noisev)\n",
    "        noisy_fake = fake.data# + torch.FloatTensor(*fake.size()).normal_(0, noise_anneal).cuda()\n",
    "        fake_output = doom_discriminator(Variable(noisy_fake).cuda())\n",
    "        \n",
    "        if random() < 0:    \n",
    "            disc_real_loss = binary_cross_entropy_loss(real_output.squeeze(), Variable(real_label.data.uniform_(0.0, 0.3)).cuda())\n",
    "            disc_fake_loss = binary_cross_entropy_loss(fake_output.squeeze(), Variable(real_label.data.uniform_(0.7, 1.2)).cuda())\n",
    "        else:\n",
    "            disc_real_loss = binary_cross_entropy_loss(real_output.squeeze(), real_label)\n",
    "            disc_fake_loss = binary_cross_entropy_loss(fake_output.squeeze(), fake_label)\n",
    "        \n",
    "        disc_real_loss.backward()\n",
    "        disc_fake_loss.backward()\n",
    "        \n",
    "        disc_loss = disc_real_loss + disc_fake_loss\n",
    "        \n",
    "        disc_opt.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        \n",
    "\n",
    "        doom_generator.zero_grad()\n",
    "        output = doom_discriminator(fake)\n",
    "        real_label = Variable(torch.FloatTensor(output.size(0)).fill_(1)).cuda()\n",
    "\n",
    "        gen_loss = binary_cross_entropy_loss(output.squeeze(), real_label)\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "\n",
    "        print(f\"\"\"[{epoch}/{NUM_ITERATIONS-1}] :: [{i}/{len(doom_loader)-1}]\n",
    "        Disc_Real_Loss: {disc_real_loss.data[0]} Disc_Fake_Loss: {disc_fake_loss.data[0]} Gen_Loss: {gen_loss.data[0]}\"\"\")\n",
    "\n",
    "    fake = doom_generator(fixed_noise)\n",
    "    utils.save_image(fake.data,\n",
    "            f'gan_files/fake_frames_after_epoch_{epoch}.png',\n",
    "            normalize = True, nrow = 6)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(doom_generator.state_dict(), f'gan_files/gen_latest.pth')\n",
    "    torch.save(doom_discriminator.state_dict(), f'gan_files/disc_latest.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
