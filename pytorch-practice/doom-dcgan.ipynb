{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle\n",
    "import imageio\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "Z_DIMENSION = 32\n",
    "BATCH_SIZE = 64\n",
    "NUM_CHANNELS = 3\n",
    "NUM_ITERATIONS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DoomFrameDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_location, transform=None):\n",
    "        \"\"\"\n",
    "        video_location (string): Path to the video file\n",
    "        transform (function, optional): Transforms to apply\n",
    "        \"\"\"\n",
    "        self.video_reader = imageio.get_reader(video_location,  'ffmpeg')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_reader)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.video_reader.get_data(idx)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "img_trans = transforms.Compose([PIL.Image.fromarray,\n",
    "                                transforms.Resize(IMG_SIZE),\n",
    "                                transforms.CenterCrop(IMG_SIZE),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                               ])\n",
    "\n",
    "doom_data = DoomFrameDataset(\"data/doom_gameplay.mp4\", img_trans)\n",
    "\n",
    "doom_loader = torch.utils.data.DataLoader(doom_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DoomGenerator(nn.Module):\n",
    "    def __init__(self, hidden_units = 128):\n",
    "        super(DoomGenerator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(Z_DIMENSION, hidden_units*8, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(hidden_units*8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_units*8, hidden_units*4, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(hidden_units*4)\n",
    "        self.deconv3 = nn.ConvTranspose2d(hidden_units*4, hidden_units*2, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(hidden_units*2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(hidden_units*2, hidden_units, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(hidden_units)\n",
    "        self.deconv5 = nn.ConvTranspose2d(hidden_units, NUM_CHANNELS, 4, 2, 1)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    def forward(self, z_data):\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(z_data)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = F.tanh(self.deconv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "doom_generator = DoomGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = torch.FloatTensor(BATCH_SIZE, Z_DIMENSION, 1, 1).normal_(0, 1)\n",
    "\n",
    "doom_generator(Variable(noise)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DoomDiscriminator(nn.Module):\n",
    "    def __init__(self, hidden_units=128):\n",
    "        super(DoomDiscriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(NUM_CHANNELS, hidden_units, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(hidden_units, hidden_units*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(hidden_units*2)\n",
    "        self.conv3 = nn.Conv2d(hidden_units*2, hidden_units*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(hidden_units*4)\n",
    "        self.conv4 = nn.Conv2d(hidden_units*4, hidden_units*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(hidden_units*8)\n",
    "        self.conv5 = nn.Conv2d(hidden_units*8, 1, 4, 1, 0)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = F.leaky_relu(self.conv1(image), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = F.sigmoid(self.conv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "doom_discriminator = DoomDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0.5833\n",
       "[torch.FloatTensor of size 1x1x1x1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doom_discriminator(Variable(doom_data[0].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doom_discriminator(doom_generator(Variable(noise))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = torch.FloatTensor(BATCH_SIZE, Z_DIMENSION, 1, 1)\n",
    "fixed_noise = Variable(torch.FloatTensor(BATCH_SIZE, Z_DIMENSION, 1, 1).normal_(0, 1))\n",
    "\n",
    "disc_opt = optim.Adam(doom_discriminator.parameters(), lr=.0005, betas=(.5, 0.999))\n",
    "gen_opt = optim.Adam(doom_generator.parameters(), lr=.0005, betas=(.5, 0.999))\n",
    "\n",
    "binary_cross_entropy_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25] :: [0/195]\n",
      "        Disc_Real_Loss: 0.005009102635085583 Disc_Fake_Loss: 0.019049787893891335 Gen_Loss: 6.314743518829346\n",
      "[0/25] :: [1/195]\n",
      "        Disc_Real_Loss: 0.013813783414661884 Disc_Fake_Loss: 7.063241004943848 Gen_Loss: 5.036657810211182\n",
      "[0/25] :: [2/195]\n",
      "        Disc_Real_Loss: 0.3938445746898651 Disc_Fake_Loss: 0.5488819479942322 Gen_Loss: 7.260267734527588\n",
      "[0/25] :: [3/195]\n",
      "        Disc_Real_Loss: 0.7492496967315674 Disc_Fake_Loss: 0.030858883634209633 Gen_Loss: 4.969048500061035\n",
      "[0/25] :: [4/195]\n",
      "        Disc_Real_Loss: 0.014431076124310493 Disc_Fake_Loss: 0.581393301486969 Gen_Loss: 4.779274940490723\n",
      "[0/25] :: [5/195]\n",
      "        Disc_Real_Loss: 0.025245795026421547 Disc_Fake_Loss: 0.05954959988594055 Gen_Loss: 4.616872310638428\n",
      "[0/25] :: [6/195]\n",
      "        Disc_Real_Loss: 0.050661876797676086 Disc_Fake_Loss: 0.1159633994102478 Gen_Loss: 3.944753885269165\n",
      "[0/25] :: [7/195]\n",
      "        Disc_Real_Loss: 0.011134237051010132 Disc_Fake_Loss: 0.4208289086818695 Gen_Loss: 4.964893817901611\n",
      "[0/25] :: [8/195]\n",
      "        Disc_Real_Loss: 0.10804731398820877 Disc_Fake_Loss: 0.03229358792304993 Gen_Loss: 5.124809265136719\n",
      "[0/25] :: [9/195]\n",
      "        Disc_Real_Loss: 0.03449239209294319 Disc_Fake_Loss: 0.08748862147331238 Gen_Loss: 4.167008876800537\n",
      "[0/25] :: [10/195]\n",
      "        Disc_Real_Loss: 0.010878807865083218 Disc_Fake_Loss: 0.4509093165397644 Gen_Loss: 6.501084327697754\n",
      "[0/25] :: [11/195]\n",
      "        Disc_Real_Loss: 0.6568068265914917 Disc_Fake_Loss: 0.006980384700000286 Gen_Loss: 5.434494972229004\n",
      "[0/25] :: [12/195]\n",
      "        Disc_Real_Loss: 0.0048452578485012054 Disc_Fake_Loss: 0.029540803283452988 Gen_Loss: 3.535736083984375\n",
      "[0/25] :: [13/195]\n",
      "        Disc_Real_Loss: 0.016823850572109222 Disc_Fake_Loss: 2.301342010498047 Gen_Loss: 5.38501501083374\n",
      "[0/25] :: [14/195]\n",
      "        Disc_Real_Loss: 0.6833212971687317 Disc_Fake_Loss: 0.01962454617023468 Gen_Loss: 4.6874308586120605\n",
      "[0/25] :: [15/195]\n",
      "        Disc_Real_Loss: 0.25670647621154785 Disc_Fake_Loss: 0.019543180242180824 Gen_Loss: 3.8198444843292236\n",
      "[0/25] :: [16/195]\n",
      "        Disc_Real_Loss: 0.02560439333319664 Disc_Fake_Loss: 0.05493180826306343 Gen_Loss: 3.24356746673584\n",
      "[0/25] :: [17/195]\n",
      "        Disc_Real_Loss: 0.01683185063302517 Disc_Fake_Loss: 0.1483115404844284 Gen_Loss: 3.2221603393554688\n",
      "[0/25] :: [18/195]\n",
      "        Disc_Real_Loss: 0.005044199526309967 Disc_Fake_Loss: 0.2050362527370453 Gen_Loss: 4.1703619956970215\n",
      "[0/25] :: [19/195]\n",
      "        Disc_Real_Loss: 0.021615169942378998 Disc_Fake_Loss: 0.0725727304816246 Gen_Loss: 4.58993673324585\n",
      "[0/25] :: [20/195]\n",
      "        Disc_Real_Loss: 0.13338077068328857 Disc_Fake_Loss: 0.049820780754089355 Gen_Loss: 4.1101603507995605\n",
      "[0/25] :: [21/195]\n",
      "        Disc_Real_Loss: 0.04245444014668465 Disc_Fake_Loss: 0.30981114506721497 Gen_Loss: 6.597267150878906\n",
      "[0/25] :: [22/195]\n",
      "        Disc_Real_Loss: 0.3630552887916565 Disc_Fake_Loss: 0.012962245382368565 Gen_Loss: 3.378699541091919\n",
      "[0/25] :: [23/195]\n",
      "        Disc_Real_Loss: 0.0069157336838543415 Disc_Fake_Loss: 1.7007112503051758 Gen_Loss: 7.77890682220459\n",
      "[0/25] :: [24/195]\n",
      "        Disc_Real_Loss: 4.272593021392822 Disc_Fake_Loss: 0.006605494301766157 Gen_Loss: 5.012975692749023\n",
      "[0/25] :: [25/195]\n",
      "        Disc_Real_Loss: 0.7436134219169617 Disc_Fake_Loss: 0.04912487044930458 Gen_Loss: 2.6064670085906982\n",
      "[0/25] :: [26/195]\n",
      "        Disc_Real_Loss: 0.10877697914838791 Disc_Fake_Loss: 0.3945021331310272 Gen_Loss: 1.7133468389511108\n",
      "[0/25] :: [27/195]\n",
      "        Disc_Real_Loss: 0.0707436203956604 Disc_Fake_Loss: 0.7597247362136841 Gen_Loss: 2.6383213996887207\n",
      "[0/25] :: [28/195]\n",
      "        Disc_Real_Loss: 0.26191025972366333 Disc_Fake_Loss: 0.1793842911720276 Gen_Loss: 2.747614622116089\n",
      "[0/25] :: [29/195]\n",
      "        Disc_Real_Loss: 0.2738519012928009 Disc_Fake_Loss: 0.317121684551239 Gen_Loss: 2.444976568222046\n",
      "[0/25] :: [30/195]\n",
      "        Disc_Real_Loss: 0.16946589946746826 Disc_Fake_Loss: 0.34079036116600037 Gen_Loss: 3.667494773864746\n",
      "[0/25] :: [31/195]\n",
      "        Disc_Real_Loss: 0.37462925910949707 Disc_Fake_Loss: 0.06438680738210678 Gen_Loss: 2.3371009826660156\n",
      "[0/25] :: [32/195]\n",
      "        Disc_Real_Loss: 0.03173530474305153 Disc_Fake_Loss: 2.8336234092712402 Gen_Loss: 6.458802700042725\n",
      "[0/25] :: [33/195]\n",
      "        Disc_Real_Loss: 4.590587139129639 Disc_Fake_Loss: 0.003622729331254959 Gen_Loss: 3.909759998321533\n",
      "[0/25] :: [34/195]\n",
      "        Disc_Real_Loss: 2.2603378295898438 Disc_Fake_Loss: 0.046886149793863297 Gen_Loss: 1.3600317239761353\n",
      "[0/25] :: [35/195]\n",
      "        Disc_Real_Loss: 0.7399285435676575 Disc_Fake_Loss: 0.4853137731552124 Gen_Loss: 0.6353045701980591\n",
      "[0/25] :: [36/195]\n",
      "        Disc_Real_Loss: 0.2501354515552521 Disc_Fake_Loss: 0.9823020696640015 Gen_Loss: 1.0472428798675537\n",
      "[0/25] :: [37/195]\n",
      "        Disc_Real_Loss: 0.2657831609249115 Disc_Fake_Loss: 0.6744517087936401 Gen_Loss: 1.589875340461731\n",
      "[0/25] :: [38/195]\n",
      "        Disc_Real_Loss: 0.5720621347427368 Disc_Fake_Loss: 0.4401133954524994 Gen_Loss: 1.4376975297927856\n",
      "[0/25] :: [39/195]\n",
      "        Disc_Real_Loss: 0.5172567367553711 Disc_Fake_Loss: 0.7111379504203796 Gen_Loss: 1.1474463939666748\n",
      "[0/25] :: [40/195]\n",
      "        Disc_Real_Loss: 0.5684993863105774 Disc_Fake_Loss: 0.8415127396583557 Gen_Loss: 1.2607755661010742\n",
      "[0/25] :: [41/195]\n",
      "        Disc_Real_Loss: 0.5918095111846924 Disc_Fake_Loss: 0.6435661911964417 Gen_Loss: 1.9353654384613037\n",
      "[0/25] :: [42/195]\n",
      "        Disc_Real_Loss: 0.533265233039856 Disc_Fake_Loss: 0.2960110008716583 Gen_Loss: 1.9967381954193115\n",
      "[0/25] :: [43/195]\n",
      "        Disc_Real_Loss: 0.4703817367553711 Disc_Fake_Loss: 0.6609067320823669 Gen_Loss: 1.8175233602523804\n",
      "[0/25] :: [44/195]\n",
      "        Disc_Real_Loss: 0.5388016104698181 Disc_Fake_Loss: 0.5637893080711365 Gen_Loss: 1.4230233430862427\n",
      "[0/25] :: [45/195]\n",
      "        Disc_Real_Loss: 0.5302157402038574 Disc_Fake_Loss: 0.9737388491630554 Gen_Loss: 2.3334453105926514\n",
      "[0/25] :: [46/195]\n",
      "        Disc_Real_Loss: 0.9907070398330688 Disc_Fake_Loss: 0.20898577570915222 Gen_Loss: 1.2252368927001953\n",
      "[0/25] :: [47/195]\n",
      "        Disc_Real_Loss: 0.1805141419172287 Disc_Fake_Loss: 1.0577540397644043 Gen_Loss: 3.1923720836639404\n",
      "[0/25] :: [48/195]\n",
      "        Disc_Real_Loss: 1.006798505783081 Disc_Fake_Loss: 0.18415167927742004 Gen_Loss: 1.383542537689209\n",
      "[0/25] :: [49/195]\n",
      "        Disc_Real_Loss: 0.4563957750797272 Disc_Fake_Loss: 0.8175280094146729 Gen_Loss: 1.9431161880493164\n",
      "[0/25] :: [50/195]\n",
      "        Disc_Real_Loss: 0.6520361304283142 Disc_Fake_Loss: 0.508158266544342 Gen_Loss: 2.520110845565796\n",
      "[0/25] :: [51/195]\n",
      "        Disc_Real_Loss: 0.5565353631973267 Disc_Fake_Loss: 0.3273446559906006 Gen_Loss: 1.6487518548965454\n",
      "[0/25] :: [52/195]\n",
      "        Disc_Real_Loss: 0.2854396104812622 Disc_Fake_Loss: 1.3781306743621826 Gen_Loss: 4.959020137786865\n",
      "[0/25] :: [53/195]\n",
      "        Disc_Real_Loss: 3.3204801082611084 Disc_Fake_Loss: 0.02100098505616188 Gen_Loss: 2.273540496826172\n",
      "[0/25] :: [54/195]\n",
      "        Disc_Real_Loss: 1.475702166557312 Disc_Fake_Loss: 0.19255121052265167 Gen_Loss: 0.6088491082191467\n",
      "[0/25] :: [55/195]\n",
      "        Disc_Real_Loss: 0.42959797382354736 Disc_Fake_Loss: 1.1420552730560303 Gen_Loss: 0.58869868516922\n",
      "[0/25] :: [56/195]\n",
      "        Disc_Real_Loss: 0.3996496796607971 Disc_Fake_Loss: 1.0170373916625977 Gen_Loss: 1.2603999376296997\n",
      "[0/25] :: [57/195]\n",
      "        Disc_Real_Loss: 0.6596749424934387 Disc_Fake_Loss: 0.3867783546447754 Gen_Loss: 1.5257071256637573\n",
      "[0/25] :: [58/195]\n",
      "        Disc_Real_Loss: 0.5648806691169739 Disc_Fake_Loss: 0.4473036527633667 Gen_Loss: 1.153017520904541\n",
      "[0/25] :: [59/195]\n",
      "        Disc_Real_Loss: 0.44880780577659607 Disc_Fake_Loss: 0.6791535019874573 Gen_Loss: 1.0906407833099365\n",
      "[0/25] :: [60/195]\n",
      "        Disc_Real_Loss: 0.5092293620109558 Disc_Fake_Loss: 0.7395014762878418 Gen_Loss: 1.448723316192627\n",
      "[0/25] :: [61/195]\n",
      "        Disc_Real_Loss: 0.5308186411857605 Disc_Fake_Loss: 0.41472217440605164 Gen_Loss: 1.6533524990081787\n",
      "[0/25] :: [62/195]\n",
      "        Disc_Real_Loss: 0.3988160192966461 Disc_Fake_Loss: 0.5767450332641602 Gen_Loss: 1.7282845973968506\n",
      "[0/25] :: [63/195]\n",
      "        Disc_Real_Loss: 0.5249657034873962 Disc_Fake_Loss: 0.47744473814964294 Gen_Loss: 2.0451016426086426\n",
      "[0/25] :: [64/195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Disc_Real_Loss: 0.5679936408996582 Disc_Fake_Loss: 0.551529586315155 Gen_Loss: 2.7228152751922607\n",
      "[0/25] :: [65/195]\n",
      "        Disc_Real_Loss: 0.7279313802719116 Disc_Fake_Loss: 0.26267021894454956 Gen_Loss: 0.8468409776687622\n",
      "[0/25] :: [66/195]\n",
      "        Disc_Real_Loss: 0.14282415807247162 Disc_Fake_Loss: 1.8172409534454346 Gen_Loss: 3.214627265930176\n",
      "[0/25] :: [67/195]\n",
      "        Disc_Real_Loss: 2.3422703742980957 Disc_Fake_Loss: 0.08540057390928268 Gen_Loss: 1.9127916097640991\n",
      "[0/25] :: [68/195]\n",
      "        Disc_Real_Loss: 1.2554121017456055 Disc_Fake_Loss: 0.23947599530220032 Gen_Loss: 0.8889126777648926\n",
      "[0/25] :: [69/195]\n",
      "        Disc_Real_Loss: 0.45191413164138794 Disc_Fake_Loss: 0.7466612458229065 Gen_Loss: 0.6345129609107971\n",
      "[0/25] :: [70/195]\n",
      "        Disc_Real_Loss: 0.27015790343284607 Disc_Fake_Loss: 0.8908170461654663 Gen_Loss: 0.8621242642402649\n",
      "[0/25] :: [71/195]\n",
      "        Disc_Real_Loss: 0.29910680651664734 Disc_Fake_Loss: 0.6630015969276428 Gen_Loss: 1.2329955101013184\n",
      "[0/25] :: [72/195]\n",
      "        Disc_Real_Loss: 0.501504123210907 Disc_Fake_Loss: 0.438264399766922 Gen_Loss: 1.3949741125106812\n",
      "[0/25] :: [73/195]\n",
      "        Disc_Real_Loss: 0.48584455251693726 Disc_Fake_Loss: 0.4421660006046295 Gen_Loss: 1.2624425888061523\n",
      "[0/25] :: [74/195]\n",
      "        Disc_Real_Loss: 0.32705578207969666 Disc_Fake_Loss: 0.5778153538703918 Gen_Loss: 1.8481926918029785\n",
      "[0/25] :: [75/195]\n",
      "        Disc_Real_Loss: 0.6144872307777405 Disc_Fake_Loss: 0.3578697144985199 Gen_Loss: 1.6058119535446167\n",
      "[0/25] :: [76/195]\n",
      "        Disc_Real_Loss: 0.3650023341178894 Disc_Fake_Loss: 1.2685610055923462 Gen_Loss: 4.01284122467041\n",
      "[0/25] :: [77/195]\n",
      "        Disc_Real_Loss: 2.0439553260803223 Disc_Fake_Loss: 0.04990416020154953 Gen_Loss: 1.9938030242919922\n",
      "[0/25] :: [78/195]\n",
      "        Disc_Real_Loss: 0.6733720898628235 Disc_Fake_Loss: 0.37233495712280273 Gen_Loss: 0.7990747690200806\n",
      "[0/25] :: [79/195]\n",
      "        Disc_Real_Loss: 0.3179115653038025 Disc_Fake_Loss: 1.1638213396072388 Gen_Loss: 1.2147369384765625\n",
      "[0/25] :: [80/195]\n",
      "        Disc_Real_Loss: 0.5003788471221924 Disc_Fake_Loss: 0.572904646396637 Gen_Loss: 1.5004334449768066\n",
      "[0/25] :: [81/195]\n",
      "        Disc_Real_Loss: 0.6803257465362549 Disc_Fake_Loss: 0.35146528482437134 Gen_Loss: 1.3719428777694702\n",
      "[0/25] :: [82/195]\n",
      "        Disc_Real_Loss: 0.4252757728099823 Disc_Fake_Loss: 0.45509374141693115 Gen_Loss: 1.378073811531067\n",
      "[0/25] :: [83/195]\n",
      "        Disc_Real_Loss: 0.5500876903533936 Disc_Fake_Loss: 0.5144343376159668 Gen_Loss: 1.4643803834915161\n",
      "[0/25] :: [84/195]\n",
      "        Disc_Real_Loss: 0.30670401453971863 Disc_Fake_Loss: 0.3919292986392975 Gen_Loss: 2.0347819328308105\n",
      "[0/25] :: [85/195]\n",
      "        Disc_Real_Loss: 0.5275427103042603 Disc_Fake_Loss: 0.26373782753944397 Gen_Loss: 1.510133147239685\n",
      "[0/25] :: [86/195]\n",
      "        Disc_Real_Loss: 0.20918245613574982 Disc_Fake_Loss: 1.030717372894287 Gen_Loss: 3.0404157638549805\n",
      "[0/25] :: [87/195]\n",
      "        Disc_Real_Loss: 1.2196824550628662 Disc_Fake_Loss: 0.12530668079853058 Gen_Loss: 1.5478254556655884\n",
      "[0/25] :: [88/195]\n",
      "        Disc_Real_Loss: 0.5978941321372986 Disc_Fake_Loss: 0.4777970612049103 Gen_Loss: 1.4533641338348389\n",
      "[0/25] :: [89/195]\n",
      "        Disc_Real_Loss: 0.287580668926239 Disc_Fake_Loss: 0.5348437428474426 Gen_Loss: 2.7987849712371826\n",
      "[0/25] :: [90/195]\n",
      "        Disc_Real_Loss: 0.4918433427810669 Disc_Fake_Loss: 0.18493084609508514 Gen_Loss: 2.482156753540039\n",
      "[0/25] :: [91/195]\n",
      "        Disc_Real_Loss: 0.16476114094257355 Disc_Fake_Loss: 0.45387718081474304 Gen_Loss: 4.29416036605835\n",
      "[0/25] :: [92/195]\n",
      "        Disc_Real_Loss: 0.5694928169250488 Disc_Fake_Loss: 0.12515805661678314 Gen_Loss: 3.15067195892334\n",
      "[0/25] :: [93/195]\n",
      "        Disc_Real_Loss: 0.2869006097316742 Disc_Fake_Loss: 0.5167791247367859 Gen_Loss: 2.8862102031707764\n",
      "[0/25] :: [94/195]\n",
      "        Disc_Real_Loss: 0.6678078770637512 Disc_Fake_Loss: 0.19226723909378052 Gen_Loss: 1.0613415241241455\n",
      "[0/25] :: [95/195]\n",
      "        Disc_Real_Loss: 0.11664103716611862 Disc_Fake_Loss: 0.9865075945854187 Gen_Loss: 3.4968860149383545\n",
      "[0/25] :: [96/195]\n",
      "        Disc_Real_Loss: 0.3381272554397583 Disc_Fake_Loss: 0.09733594954013824 Gen_Loss: 3.234395980834961\n",
      "[0/25] :: [97/195]\n",
      "        Disc_Real_Loss: 0.4405953288078308 Disc_Fake_Loss: 0.326521098613739 Gen_Loss: 2.3736507892608643\n",
      "[0/25] :: [98/195]\n",
      "        Disc_Real_Loss: 0.5846505165100098 Disc_Fake_Loss: 0.4360474944114685 Gen_Loss: 2.479623556137085\n",
      "[0/25] :: [99/195]\n",
      "        Disc_Real_Loss: 0.37239864468574524 Disc_Fake_Loss: 0.6121079325675964 Gen_Loss: 3.5368499755859375\n",
      "[0/25] :: [100/195]\n",
      "        Disc_Real_Loss: 1.2337726354599 Disc_Fake_Loss: 0.11294535547494888 Gen_Loss: 0.742337703704834\n",
      "[0/25] :: [101/195]\n",
      "        Disc_Real_Loss: 0.06825664639472961 Disc_Fake_Loss: 3.111213445663452 Gen_Loss: 4.302392482757568\n",
      "[0/25] :: [102/195]\n",
      "        Disc_Real_Loss: 0.9177100658416748 Disc_Fake_Loss: 0.04889259487390518 Gen_Loss: 3.5586884021759033\n",
      "[0/25] :: [103/195]\n",
      "        Disc_Real_Loss: 0.9323628544807434 Disc_Fake_Loss: 0.12537404894828796 Gen_Loss: 1.7671983242034912\n",
      "[0/25] :: [104/195]\n",
      "        Disc_Real_Loss: 0.4990787208080292 Disc_Fake_Loss: 0.4558594226837158 Gen_Loss: 1.2268909215927124\n",
      "[0/25] :: [105/195]\n",
      "        Disc_Real_Loss: 0.28675806522369385 Disc_Fake_Loss: 0.6716051697731018 Gen_Loss: 1.861703634262085\n",
      "[0/25] :: [106/195]\n",
      "        Disc_Real_Loss: 0.2766750454902649 Disc_Fake_Loss: 0.48208361864089966 Gen_Loss: 2.205413818359375\n",
      "[0/25] :: [107/195]\n",
      "        Disc_Real_Loss: 0.5801893472671509 Disc_Fake_Loss: 0.3467146158218384 Gen_Loss: 2.0301315784454346\n",
      "[0/25] :: [108/195]\n",
      "        Disc_Real_Loss: 0.45620736479759216 Disc_Fake_Loss: 0.3465806245803833 Gen_Loss: 1.8893836736679077\n",
      "[0/25] :: [109/195]\n",
      "        Disc_Real_Loss: 0.6009760499000549 Disc_Fake_Loss: 0.37572047114372253 Gen_Loss: 1.9569288492202759\n",
      "[0/25] :: [110/195]\n",
      "        Disc_Real_Loss: 0.4071239233016968 Disc_Fake_Loss: 0.406965434551239 Gen_Loss: 2.5681450366973877\n",
      "[0/25] :: [111/195]\n",
      "        Disc_Real_Loss: 0.24729835987091064 Disc_Fake_Loss: 0.29239287972450256 Gen_Loss: 2.978605270385742\n",
      "[0/25] :: [112/195]\n",
      "        Disc_Real_Loss: 0.3079257607460022 Disc_Fake_Loss: 0.19446168839931488 Gen_Loss: 2.768697738647461\n",
      "[0/25] :: [113/195]\n",
      "        Disc_Real_Loss: 0.18655972182750702 Disc_Fake_Loss: 0.2154380828142166 Gen_Loss: 3.571305751800537\n",
      "[0/25] :: [114/195]\n",
      "        Disc_Real_Loss: 0.5384231805801392 Disc_Fake_Loss: 0.12536996603012085 Gen_Loss: 2.266982078552246\n",
      "[0/25] :: [115/195]\n",
      "        Disc_Real_Loss: 0.08690337091684341 Disc_Fake_Loss: 1.4342659711837769 Gen_Loss: 6.047276020050049\n",
      "[0/25] :: [116/195]\n",
      "        Disc_Real_Loss: 2.6065852642059326 Disc_Fake_Loss: 0.0109641645103693 Gen_Loss: 2.945878744125366\n",
      "[0/25] :: [117/195]\n",
      "        Disc_Real_Loss: 0.9736263751983643 Disc_Fake_Loss: 0.27676713466644287 Gen_Loss: 0.6731540560722351\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_ITERATIONS):\n",
    "    for i, data in enumerate(doom_loader):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        doom_discriminator.zero_grad()\n",
    "        inputv = Variable(data)\n",
    "        real_label = Variable(torch.FloatTensor(data.size(0)).fill_(1))\n",
    "        \n",
    "        \n",
    "\n",
    "        output = doom_discriminator(inputv)\n",
    "        disc_real_loss = binary_cross_entropy_loss(output.squeeze(), real_label)\n",
    "        disc_real_loss.backward()\n",
    "\n",
    "        # train with fake\n",
    "        noise.normal_(0, 1)\n",
    "        noisev = Variable(noise)\n",
    "        fake = doom_generator(noisev)\n",
    "        output = doom_discriminator(fake.detach())\n",
    "        fake_label = Variable(torch.FloatTensor(noise.size(0)).fill_(0)) \n",
    "        disc_fake_loss = binary_cross_entropy_loss(output.squeeze(), fake_label)\n",
    "        disc_fake_loss.backward()\n",
    "        disc_loss = disc_real_loss + disc_fake_loss\n",
    "        disc_opt.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        doom_generator.zero_grad()\n",
    "        output = doom_discriminator(fake)\n",
    "        real_label = Variable(torch.FloatTensor(output.size(0)).fill_(1))\n",
    "\n",
    "        gen_loss = binary_cross_entropy_loss(output.squeeze(), real_label)\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        print(f\"\"\"[{epoch}/{NUM_ITERATIONS}] :: [{i}/{len(doom_loader)}]\n",
    "        Disc_Real_Loss: {disc_real_loss.data[0]} Disc_Fake_Loss: {disc_fake_loss.data[0]} Gen_Loss: {gen_loss.data[0]}\"\"\")\n",
    "        if i % 100 == 0:\n",
    "            utils.save_image(data,\n",
    "                    'gan_files/real_samples.png',\n",
    "                    normalize=True)\n",
    "            fake = doom_generator(fixed_noise)\n",
    "            utils.save_image(fake.data,\n",
    "                    f'gan_files/fake_samples_epoch_{epoch}.png',\n",
    "                    normalize=True)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(doom_generator.state_dict(), f'gan_files/gen_epoch_{epoch}.pth')\n",
    "    torch.save(doom_discriminator.state_dict(), f'gan_files/disc_epoch_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
